<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-07-17 Fr 00:31 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Machine Learning</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="sx" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Machine Learning</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org4dd512b">Math for ML</a>
<ul>
<li><a href="#org72c7fea">Bayes's Rule</a></li>
<li><a href="#orgec438e6">Kovarianz Matrix</a></li>
<li><a href="#orgc4aa8b3">Multi variable Gaussian distribution</a></li>
<li><a href="#orgfd4ff24">Mahalanobis distance</a></li>
<li><a href="#orgf84748a">precision 查准率 recall 查全率</a></li>
</ul>
</li>
<li><a href="#orgccfb525">Algorithms</a>
<ul>
<li><a href="#org63b707e">OLS 正规化方程</a></li>
<li><a href="#orgc03ee6f">朴素贝叶斯</a></li>
<li><a href="#org3bef8ce">Decision List</a></li>
<li><a href="#orgdff9466">Decision tree</a>
<ul>
<li><a href="#orgdaa48db">方法描述和变量</a></li>
<li><a href="#org6805291">预剪枝和后剪枝</a></li>
<li><a href="#org3c493e0">属性有连续值和缺失值</a></li>
<li><a href="#orgcc44d9e">多变量决策</a></li>
</ul>
</li>
<li><a href="#orgc1c08d8">Random Forest</a></li>
<li><a href="#org2ad3f4d">gradient decent</a></li>
<li><a href="#orgfab9572">linear regression</a></li>
<li><a href="#org094b40f">Support Vector Machine</a></li>
<li><a href="#org7be53a6">logical regression</a></li>
<li><a href="#orgfba16a8">Neural network</a></li>
<li><a href="#org9244559">Conversational neural Network</a></li>
<li><a href="#org01864d4">linear Discriminate Analysis(Fisher)</a>
<ul>
<li><a href="#org166a11f">算法简介</a></li>
</ul>
</li>
<li><a href="#orge37e9d4">Principe Component Analysis</a></li>
<li><a href="#org9f2fa41">K-Means</a>
<ul>
<li><a href="#orgc6d33d9">算法介绍</a></li>
<li><a href="#org91b2b71">code</a></li>
</ul>
</li>
<li><a href="#org9cb622f">EM algorithms</a></li>
<li><a href="#org353caeb">link</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org4dd512b" class="outline-2">
<h2 id="org4dd512b">Math for ML</h2>
<div class="outline-text-2" id="text-org4dd512b">
</div>
<div id="outline-container-org72c7fea" class="outline-3">
<h3 id="org72c7fea">Bayes's Rule</h3>
<div class="outline-text-3" id="text-org72c7fea">
<p>
\[ p(x) = \sum_{y} p(X,Y) \]
</p>

<p>
if x and y are independent:
\[ p(x,y) =  p(y)p(x) = p(x) p(y) = p(y,x) \] 
</p>

<p>
条件概论公式 + 全概率公式 = 贝叶斯公式
\[ P(y|x) = \frac{ P(x|y) P(y)}{P(x)}\]
</p>
<pre class="example">
+
</pre>

<p>
\[ p(x,y)  =  p(x|y) p(y) \]
\[ p(y,x) = p(y|x)p(x) \]
</p>
<pre class="example">
=
</pre>
<p>
\[ P(y|x) = \frac{ P(x,y)}{P(x)}\]
</p>

<p>
条件概率 = 联合概率/边缘概率
</p>

<p>
先验概率和后验概率都是条件概率，但是条件已知是先验
</p>
</div>
</div>


<div id="outline-container-orgec438e6" class="outline-3">
<h3 id="orgec438e6">Kovarianz Matrix</h3>
<div class="outline-text-3" id="text-orgec438e6">
<p>
seeing link : <a href="https://scofild429.github.io/subjects/statistik.html">Statistik web</a>
org link : <a href="file:///home/sx/Dropbox/subjects/statistik.html">Startistik org</a>
</p>

<p>
for i = {1&#x2026;n}, \(x_{i}\) is a random variable, which belong to
Gaussian distribution
</p>

<p>
set 
 \[ X = \left( \begin{aligned}  x_{1} \\ x_{2}\\ . \\. \\x_{n}  \end{aligned}\right) \]
</p>


<p>
\[ \bar{X} = \left( \begin{aligned}  \bar{x}_{1}
\\ \bar{x}_{2}\\ . \\. \\ \bar{x}_{n}  \end{aligned} \right) \]
co-variance matrix \(\Sigma = E [(X-\bar{X})(X-\bar{X})^{T} ]\)
</p>

\begin{equation}
\Sigma = 
  \left(
  \begin{array}{c}
          x_{1}-\bar{x}_{1} \\
          x_{2}-\bar{x}_{2} \\
          x_{3}-\bar{x}_{3} \\
          ..                \\
          x_{n}-\bar{x}_{n} 
 \end{array}
 \right)
   \left(
  \begin{array}{ccccc}
          x_{1}-\bar{x}_{1} &
          x_{2}-\bar{x}_{2} &
          x_{3}-\bar{x}_{3} &
          ..                &
          x_{n}-\bar{x}_{n} 
  \end{array}
  \right)
\end{equation}
<p>
对角线上是对应元素的方差，其他是相对于两个元素的协方差
</p>
</div>
</div>

<div id="outline-container-orgc4aa8b3" class="outline-3">
<h3 id="orgc4aa8b3">Multi variable Gaussian distribution</h3>
<div class="outline-text-3" id="text-orgc4aa8b3">
<p>
seeing the link 知乎  <a href="https://zhuanlan.zhihu.com/p/58987388">zhihu link</a>
</p>

<p>
\[
{\displaystyle f_{\mathbf {X} }(x_{1},\ldots ,x_{k})={\frac {\exp
\left(-{\frac {1}{2}}({\mathbf {x} }-{\boldsymbol {\mu }})^{\mathrm
{T} }{\boldsymbol {\Sigma }}^{-1}({\mathbf {x} }-{\boldsymbol {\mu
}})\right)}{\sqrt {(2\pi )^{k}|{\boldsymbol {\Sigma
}}|}}}}
\]
</p>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">gaussian</span>(x,mean,cov):
    <span style="color: #7590db;">dim</span> = np.shape(cov)[0] <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">&#32500;&#24230;</span>
    <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">&#20043;&#25152;&#20197;&#21152;&#20837;&#21333;&#20301;&#30697;&#38453;&#26159;&#20026;&#20102;&#38450;&#27490;&#34892;&#21015;&#24335;&#20026;0&#30340;&#24773;&#20917;</span>
    <span style="color: #7590db;">covdet</span> = np.linalg.det(cov+np.eye(dim)*0.01) <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#34892;&#21015;&#24335;</span>
    <span style="color: #7590db;">covinv</span> = np.linalg.inv(cov+np.eye(dim)*0.01) <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#36870;</span>
    <span style="color: #7590db;">xdiff</span> = x - mean
    <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">&#27010;&#29575;&#23494;&#24230;</span>
    <span style="color: #7590db;">prob</span> = 1.0/np.power(2*np.pi,1.0*dim/2)/np.sqrt(np.<span style="color: #4f97d7;">abs</span>(covdet))*np.exp(-1.0/2*np.dot(np.dot(xdiff,covinv),xdiff))
    <span style="color: #4f97d7; font-weight: bold;">return</span> prob

</pre>
</div>
</div>
</div>

<div id="outline-container-orgfd4ff24" class="outline-3">
<h3 id="orgfd4ff24">Mahalanobis distance</h3>
<div class="outline-text-3" id="text-orgfd4ff24">
<p>
\[ D = \sqrt{ZZ^{T}} \]
马氏距离所使用的变换\[ Z = B^{-1}(X - \mu) \],
\[ ZZ^{T} = \left(-{\frac {1}{2}}({\mathbf {x} }-{\boldsymbol {\mu }})^{\mathrm
{T} }{\boldsymbol {\Sigma }}^{-1}({\mathbf {x} }-{\boldsymbol {\mu
}})\right)
\]
\[ \Sigma = \sum U \Lambda U^{T} \]
\[ \Sigma^{-1} = \sum U \Lambda^{-1} U^{T} \]
关于新的坐标，U 是变换的旋转，\(\Lambda\) 是基底的延伸，\((x-\mu)\) 是在其
上的投影，此后，在新坐标上，即为多变量，标准，不相关高斯分布
</p>
</div>
</div>

<div id="outline-container-orgf84748a" class="outline-3">
<h3 id="orgf84748a">precision 查准率 recall 查全率</h3>
<div class="outline-text-3" id="text-orgf84748a">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">TPR</th>
<th scope="col" class="org-left">recall 查全 R</th>
<th scope="col" class="org-left">predict positive 测正 &amp;  实正 actually positive</th>
<th scope="col" class="org-left">predict negative 测反 &amp; 实正  actually positive</th>
</tr>

<tr>
<th scope="col" class="org-left">FPR</th>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">predict positive 测正 &amp;  实反 actually negative</th>
<th scope="col" class="org-left">predict negative  测反 &amp; 实反 actually negative</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">precision 查准 P</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>

<p>
R-P Couve : R P
ROC couve : FPR TPR
</p>

<p>
\[ F_{1} = \frac{1}{2} \cdot (\frac{1}{P}+\frac{1}{R})\]
\[ F_{\beta} = \frac{1}{\beta^{2}} \cdot
(\frac{\beta^{2}}{P}+\frac{1}{R})\]
</p>

<p>
关联性属性 ： 高中低 （3,2,1）
非关联性属性： 猪狗羊 （(1,0,0), (0,1,0),(0,0,1)）
</p>
</div>
</div>
</div>




<div id="outline-container-orgccfb525" class="outline-2">
<h2 id="orgccfb525">Algorithms</h2>
<div class="outline-text-2" id="text-orgccfb525">
</div>
<div id="outline-container-org63b707e" class="outline-3">
<h3 id="org63b707e">OLS 正规化方程</h3>
<div class="outline-text-3" id="text-org63b707e">
<pre class="example">
正则化方程的推导，用高斯分布的多变量分布的Maxisum likelihood,能一起求
得对weight和bias值 : 
但是要添加一列1到 train 和 test，至于在前面还是后面有点怪异。
目前认为，在后面的话，多变量和参数可以按需求访问
</pre>

<p>
\[\theta = (X^{T}X)^{-1}X^{T}y \]
</p>


<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> numpy <span style="color: #4f97d7; font-weight: bold;">as</span> np
<span style="color: #4f97d7; font-weight: bold;">import</span> random
<span style="color: #4f97d7; font-weight: bold;">from</span> sklearn <span style="color: #4f97d7; font-weight: bold;">import</span> linear_model
<span style="color: #7590db;">testsize</span> = 5

<span style="color: #7590db;">x</span> = np.array([a <span style="color: #4f97d7; font-weight: bold;">for</span> a <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100)])
<span style="color: #7590db;">onesx</span> = np.ones(x.shape)
<span style="color: #7590db;">X</span> = np.c_[x,onesx]
<span style="color: #7590db;">y</span> = np.array([a*5 + 20 + random.randint(0,3) <span style="color: #4f97d7; font-weight: bold;">for</span> a <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100)])
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"the X shape is {}, and y shape is {}"</span>.<span style="color: #4f97d7;">format</span>(X.shape, y.shape))

<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">weight = np.dot(np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T), y)</span>
<span style="color: #7590db;">weight</span> = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)

<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"OLS : the weight is{}, and the bais is {} "</span>.<span style="color: #4f97d7;">format</span>(weight[:-1], weight[-1]))
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"the predect of 5 ele is {}"</span>.<span style="color: #4f97d7;">format</span>(np.dot(np.c_[np.arange(testsize),np.ones(testsize)], weight)))


</pre>
</div>

<pre class="example">
也可以是对变量 with multi variables
</pre>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> numpy <span style="color: #4f97d7; font-weight: bold;">as</span> np
<span style="color: #4f97d7; font-weight: bold;">import</span> random
<span style="color: #4f97d7; font-weight: bold;">from</span> sklearn <span style="color: #4f97d7; font-weight: bold;">import</span> linear_model
<span style="color: #7590db;">testsize</span> = 5

<span style="color: #7590db;">x</span> = np.array([a <span style="color: #4f97d7; font-weight: bold;">for</span> a <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100)])
<span style="color: #7590db;">onesx</span> = np.ones(x.shape)
<span style="color: #7590db;">X</span> = np.c_[onesx, x, 2*x]
<span style="color: #7590db;">y</span> = np.array([a*5 + 20 + random.randint(0,3) <span style="color: #4f97d7; font-weight: bold;">for</span> a <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100)])
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"the X shape is {}, and y shape is {}"</span>.<span style="color: #4f97d7;">format</span>(X.shape, y.shape))

<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">ordinary  least squares (&#27491;&#35268;&#21270;&#26041;&#27861;&#65289;</span>
<span style="color: #7590db;">weight</span> = np.dot(np.dot(np.linalg.pinv(np.dot(X.T, X)), X.T), y)
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"OLS : the weight is{}, and the bais is {} "</span>.<span style="color: #4f97d7;">format</span>(weight[:-1], weight[-1]))
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"the predect of 5 ele is {}"</span>.<span style="color: #4f97d7;">format</span>(np.dot(np.c_[np.arange(testsize), np.arange(testsize),np.ones(testsize)], weight)))


</pre>
</div>
</div>
</div>


<div id="outline-container-orgc03ee6f" class="outline-3">
<h3 id="orgc03ee6f">朴素贝叶斯</h3>
<div class="outline-text-3" id="text-orgc03ee6f">
<p>
假设各个属性完全独立
要判断某示例的分类，分别计算出该示例在每个分类中的概论乘以该类别中该示
例的各种属性出现的条件概论， 谁大选谁。（注意样本不足引起的某属性的条
件为零）
</p>
</div>
</div>



<div id="outline-container-org3bef8ce" class="outline-3">
<h3 id="org3bef8ce">Decision List</h3>
<div class="outline-text-3" id="text-org3bef8ce">
<p>
(f1,v1),(f2,v2)&#x2026;.(fr,vr)
fi is a term in CNF, vi belongs {0,1}, and the last term fr is always
true. and each term can be viewed as if else extended. if fi is
matched, so vi is its value.
</p>

<pre class="example">
for 0&lt;k&lt;n, k-CNF and k-DNF are proper 


</pre>
</div>
</div>


<div id="outline-container-orgdff9466" class="outline-3">
<h3 id="orgdff9466">Decision tree</h3>
<div class="outline-text-3" id="text-orgdff9466">
</div>
<div id="outline-container-orgdaa48db" class="outline-4">
<h4 id="orgdaa48db">方法描述和变量</h4>
<div class="outline-text-4" id="text-orgdaa48db">
<p>
在训练集内以最大信息增益来确定划分属性，在各个子区内再重复剩下的属性
</p>

<p>
信息熵
\[ Ent(D)=-\sum^{y}_{k=1}p_{k}log_{2}^{p_{k}}\]
</p>

<p>
信息熵增益
\[ Gain(D,a) = Ent(D)-\sum^{V}_{v=1}\frac{|D^{v}|}{|D|}Ent(D^{v}) \]
</p>

<p>
吉尼系数
\[ Gini(D) = \sum^{|y|}_{k=1}\sum_{k^{'}\not = k} p_{k}p_{k^{'}} = 1- \sum^{|y|}_{k=1}p_{k}^{2}\]
</p>
</div>
</div>

<div id="outline-container-org6805291" class="outline-4">
<h4 id="org6805291">预剪枝和后剪枝</h4>
<div class="outline-text-4" id="text-org6805291">
<p>
在利用训练集的最大信息增益确定划分属性后，用验证集来检验划分，如果验证
集的信息熵增加，（泛化结果不好)否定此次划分，设为叶节点
</p>

<p>
后剪枝是在这个树完成后，用验证集去检验每一个内节点，从下到上，如果去掉
该划分有更小的信息熵，则废除该划分。
</p>
</div>
</div>

<div id="outline-container-org3c493e0" class="outline-4">
<h4 id="org3c493e0">属性有连续值和缺失值</h4>
<div class="outline-text-4" id="text-org3c493e0">
<p>
连续值离散化：排列该属性的所有取值n个，在n-1个区间中去中间值为离散值，
遍历所有离散值，找到最大信息增益的离散值，作二分。
</p>

<p>
缺失值，取出该属性的非缺失子集，再配以相应的比率计算信息增益，处理和以
前一样。如果选出的划分属性有缺失值，则给划分不作用到缺失样本，复制到每
个划分子集
</p>
</div>
</div>
<div id="outline-container-orgcc44d9e" class="outline-4">
<h4 id="orgcc44d9e">多变量决策</h4>
<div class="outline-text-4" id="text-orgcc44d9e">
<p>
每个划分属性是多个属性（变量）的线性组合
</p>
</div>
</div>
</div>


<div id="outline-container-orgc1c08d8" class="outline-3">
<h3 id="orgc1c08d8">Random Forest</h3>
</div>

<div id="outline-container-org2ad3f4d" class="outline-3">
<h3 id="org2ad3f4d">gradient decent</h3>
<div class="outline-text-3" id="text-org2ad3f4d">
<p>
当数据点很多是，正则化方法计算量将非常大，此时较多使用梯度下降
</p>

<pre class="example">
sklearn API
</pre>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #4f97d7; font-weight: bold;">import</span> numpy <span style="color: #4f97d7; font-weight: bold;">as</span> np
<span style="color: #4f97d7; font-weight: bold;">import</span> random
<span style="color: #4f97d7; font-weight: bold;">from</span> sklearn <span style="color: #4f97d7; font-weight: bold;">import</span> linear_model
<span style="color: #7590db;">testsize</span> = 5

<span style="color: #7590db;">x</span> = np.array([a <span style="color: #4f97d7; font-weight: bold;">for</span> a <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100)])
<span style="color: #7590db;">onesx</span> = np.ones(x.shape)
<span style="color: #7590db;">X</span> = np.c_[x, 2*x, onesx]
<span style="color: #7590db;">y</span> = np.array([a*5 + 20 + random.randint(0,3) <span style="color: #4f97d7; font-weight: bold;">for</span> a <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100)])
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"the X shape is {}, and y shape is {}"</span>.<span style="color: #4f97d7;">format</span>(X.shape, y.shape))

<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">Sklearn API</span>
<span style="color: #7590db;">reg</span> = linear_model.LinearRegression()
<span style="color: #7590db;">model</span> = reg.fit(X,y)
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"Sklearn: the weith is {}, and the intercept is {}"</span>.<span style="color: #4f97d7;">format</span>(model.coef_[:-1] ,model.intercept_))
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"the predect of 3 ele is {}"</span>.<span style="color: #4f97d7;">format</span>(model.predict(np.c_[np.arange(testsize), np.arange(testsize),np.ones(testsize)])))


<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">manual </span>
<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">featureNormalize</span>(X):
    (m,n) = X.shape
    <span style="color: #7590db;">X_norm</span> = X
    <span style="color: #7590db;">mu</span> = np.zeros(n);
    <span style="color: #7590db;">sigma</span> = np.zeros(n);
    <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(n):
        <span style="color: #7590db;">mu</span>[i] = np.mean(X[:,i])
        <span style="color: #7590db;">sigma</span>[i] = np.std(X[:,i])
        <span style="color: #7590db;">X_norm</span>[:,i] = (X_norm[:,i]-mu[i])/sigma[i]
    <span style="color: #4f97d7; font-weight: bold;">return</span> X_norm
<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">computeCost</span>(X, y, theta):
    <span style="color: #4f97d7; font-weight: bold;">return</span> np.<span style="color: #4f97d7;">sum</span>((np.dot(X,theta) -y)**2)/(2*<span style="color: #4f97d7;">len</span>(y));

<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">gradientDescent</span>(X, y, theta, alpha, num_iters):
    <span style="color: #7590db;">m</span> = <span style="color: #4f97d7;">len</span>(y)
    <span style="color: #7590db;">J_history</span> = np.zeros(num_iters);
    <span style="color: #7590db;">theta_len</span> = <span style="color: #4f97d7;">len</span>(theta);
    <span style="color: #4f97d7; font-weight: bold;">for</span> num_iter <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(num_iters):
        <span style="color: #7590db;">theta</span> = theta - (alpha/m)*np.dot(X.T,(np.dot(X,theta).reshape(-1)-y))
        <span style="color: #7590db;">J_history</span>[num_iter] = computeCost(X, y, theta)
    <span style="color: #4f97d7; font-weight: bold;">return</span> theta, J_history

<span style="color: #7590db;">alpha</span> = 0.0001
<span style="color: #7590db;">num_iters</span> = 400000
<span style="color: #7590db;">theta</span> = np.zeros(2+1)
<span style="color: #7590db;">theta</span>, <span style="color: #7590db;">J_history</span> = gradientDescent(X, y, theta, alpha, num_iters)
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"Greadient decent: the weight is {}, and the intercept is {}"</span>.<span style="color: #4f97d7;">format</span>(theta[:-1],theta[-1]))
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"the predect of 3 ele is {}"</span>.<span style="color: #4f97d7;">format</span>(np.dot(np.c_[np.arange(testsize), np.arange(testsize),np.ones(testsize)], theta)))
</pre>
</div>
</div>
</div>



<div id="outline-container-orgfab9572" class="outline-3">
<h3 id="orgfab9572">linear regression</h3>
</div>

<div id="outline-container-org094b40f" class="outline-3">
<h3 id="org094b40f">Support Vector Machine</h3>
</div>

<div id="outline-container-org7be53a6" class="outline-3">
<h3 id="org7be53a6">logical regression</h3>
</div>

<div id="outline-container-orgfba16a8" class="outline-3">
<h3 id="orgfba16a8">Neural network</h3>
</div>

<div id="outline-container-org9244559" class="outline-3">
<h3 id="org9244559">Conversational neural Network</h3>
</div>

<div id="outline-container-org01864d4" class="outline-3">
<h3 id="org01864d4">linear Discriminate Analysis(Fisher)</h3>
<div class="outline-text-3" id="text-org01864d4">
</div>
<div id="outline-container-org166a11f" class="outline-4">
<h4 id="org166a11f">算法简介</h4>
<div class="outline-text-4" id="text-org166a11f">
<p>
输入为j=0，1类样本，每类分别 \(N_{j}\) 个样本
\(\mu_j = \frac{1}{N_{j}} \sum x\) \(x \in N_{j}\)
\(\Sigma_{j} = \sum(x-\mu_{j})(x-\mu_{j})^{T}\), \(x \in N_{j}\)
</p>

<p>
\(argmax(J) = \frac{\omega^{T} (\mu_0-\mu_1)(\mu_0-\mu_1)^T
\omega}{\omega^T(\Sigma_0+\Sigma_1)\omega } =  \frac{\omega^{T} S_{b}
\omega}{\omega^T S_{w} \omega }\)
</p>
</div>
</div>
</div>





<div id="outline-container-orge37e9d4" class="outline-3">
<h3 id="orge37e9d4">Principe Component Analysis</h3>
</div>

<div id="outline-container-org9f2fa41" class="outline-3">
<h3 id="org9f2fa41">K-Means</h3>
<div class="outline-text-3" id="text-org9f2fa41">
</div>
<div id="outline-container-orgc6d33d9" class="outline-4">
<h4 id="orgc6d33d9">算法介绍</h4>
<div class="outline-text-4" id="text-orgc6d33d9">
<p>
输入样本集 D: \(x_{1}, x_{1}, x_{2},,,x_{m}\)
聚类数 k, 
最大迭代数 N,
期望输出: \(C_{1}, C_{2},,,C_{k}\)
</p>

<p>
随机初始化k个聚类中心，并作不同类别的标记
for i= 1,2,..N:
    初始化所有C
    计算每个点到每个中心的距离，并被最小距离的聚类中心标记
    对于所有相同标记的聚类更新中心，再重复上一步骤，直到没有变化为止
</p>
</div>
</div>

<div id="outline-container-org91b2b71" class="outline-4">
<h4 id="org91b2b71">code</h4>
<div class="outline-text-4" id="text-org91b2b71">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> random
<span style="color: #4f97d7; font-weight: bold;">import</span> numpy <span style="color: #4f97d7; font-weight: bold;">as</span> np
<span style="color: #4f97d7; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #4f97d7; font-weight: bold;">as</span> plt

<span style="color: #7590db;">b</span> = []
<span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100):
    <span style="color: #7590db;">a</span> = np.array(<span style="color: #4f97d7;">list</span>([(20,50),(30,10),(60,30)]))
    <span style="color: #4f97d7; font-weight: bold;">for</span> j <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(a.shape[0]):
        <span style="color: #4f97d7; font-weight: bold;">for</span> k <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(a.shape[1]):
            a[j][k] += random.randint(0,30)
            b.append(a[j])

<span style="color: #7590db;">b</span> = np.array(b)
plt.plot(b[:,0], b[:,1], <span style="color: #2d9574;">'ro'</span>)
plt.title(<span style="color: #2d9574;">"toy data"</span>)
plt.show()


<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">sklearn API</span>
<span style="color: #4f97d7; font-weight: bold;">from</span> sklearn.cluster <span style="color: #4f97d7; font-weight: bold;">import</span> KMeans
<span style="color: #7590db;">y_pred</span> = KMeans(n_clusters=3, random_state=9).fit_predict(b)
plt.scatter(b[:, 0], b[:, 1], c=y_pred)
plt.title(<span style="color: #2d9574;">"toy data with sklearn API"</span>)
plt.show()

<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">manual</span>
<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">findClosestCentroids</span>(X, centroids):
    <span style="color: #7590db;">distance</span> = np.zeros((<span style="color: #4f97d7;">len</span>(X),<span style="color: #4f97d7;">len</span>(centroids)))
    <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(<span style="color: #4f97d7;">len</span>(X)):
        <span style="color: #4f97d7; font-weight: bold;">for</span> j <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(<span style="color: #4f97d7;">len</span>(centroids)):
            <span style="color: #7590db;">distance</span>[i,j] = np.linalg.norm(X[i,:]-centroids[j,:])
    <span style="color: #4f97d7; font-weight: bold;">return</span> np.argmin(distance,axis=1)

<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">computeCentroids</span>(X, idx, K):
    <span style="color: #7590db;">centroids</span> = np.zeros((K,X.shape[1]))
    <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(K):
        <span style="color: #7590db;">centroids</span>[i,:] = np.mean(X[idx == i],axis = 0)
    <span style="color: #4f97d7; font-weight: bold;">return</span> centroids


<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">runkMeans</span>(X,K,max_iters):
    <span style="color: #7590db;">indexs</span> = np.random.choice(np.array(<span style="color: #4f97d7;">range</span>(<span style="color: #4f97d7;">len</span>(X))), K,replace=<span style="color: #a45bad;">False</span>)
    <span style="color: #7590db;">centroids</span> = X[indexs]
    <span style="color: #4f97d7; font-weight: bold;">for</span> max_iter <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(max_iters):
        <span style="color: #7590db;">idx</span> = findClosestCentroids(X, centroids)
        <span style="color: #7590db;">centroids</span> = computeCentroids(X, idx, K)
        <span style="color: #7590db;">colors</span> = [<span style="color: #2d9574;">''</span>,<span style="color: #2d9574;">''</span>,<span style="color: #2d9574;">''</span>]
        <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(K):
            plt.scatter(X[idx==i, 0], X[idx==i, 1])
        plt.scatter(centroids[:, 0], centroids[:, 1], c=<span style="color: #2d9574;">'r'</span>)
        plt.title(<span style="color: #2d9574;">"toy data with manual {} time"</span>.<span style="color: #4f97d7;">format</span>(max_iter))
        plt.show()
<span style="color: #7590db;">K</span> = 3
<span style="color: #7590db;">max_iters</span> = 3
runkMeans(b,K,max_iters)

</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-org9cb622f" class="outline-3">
<h3 id="org9cb622f">EM algorithms</h3>
</div>

<div id="outline-container-org353caeb" class="outline-3">
<h3 id="org353caeb">link</h3>
<div class="outline-text-3" id="text-org353caeb">
<p>
机器学习代码和课件可在此下 <sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>
</p>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
<a href="https://jia666-my.sharepoint.com/:f:/g/personal/hmp121_xkx_me/EsaG70R5NXdMgC7V1aYwyQcB5C-8nFiSYTWG3Uur9ZvbEA?e=1D2uPf">https://jia666-my.sharepoint.com/:f:/g/personal/hmp121_xkx_me/EsaG70R5NXdMgC7V1aYwyQcB5C-8nFiSYTWG3Uur9ZvbEA?e=1D2uPf</a>
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="author">Author: sx</p>
<p class="date">Created: 2020-07-17 Fr 00:31</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>

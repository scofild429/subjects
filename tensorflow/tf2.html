<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-06-29 Mo 22:28 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>tf2</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="sx" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://fniessen.github.io/org-html-themes/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/styles/lib/js/jquery.stickytableheaders.min.js"></script>
<script type="text/javascript" src="https://fniessen.github.io/org-html-themes/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2020 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">tf2</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org6d37b5c">Check GPU</a></li>
<li><a href="#orgb4cd477">Tensorflow foundation</a>
<ul>
<li><a href="#orgcc04d4b">数值类型</a></li>
<li><a href="#org94b026c">Reference(,) and Segment(:)</a></li>
<li><a href="#org6b744f4">改变视图</a>
<ul>
<li><a href="#org5e5eb69">增加维度</a></li>
<li><a href="#orgfdde96c">删除维度</a></li>
</ul>
</li>
<li><a href="#org474747b">交换维度</a></li>
<li><a href="#orgdb7cdae">Broadcasting</a></li>
<li><a href="#org58d2f9d">tile</a></li>
<li><a href="#orgceea294">Concatenate &amp; Stack &amp; Split &amp; unstack</a></li>
<li><a href="#orgb57af20">Statistik</a></li>
<li><a href="#org67784d8">Padding</a></li>
<li><a href="#org8ed14de">advance manipulation</a>
<ul>
<li><a href="#org04e04d4">tf.minimum</a></li>
<li><a href="#org61dd24a">tf.gather</a></li>
<li><a href="#org15b5d72">tf.gather<sub>nd</sub></a></li>
<li><a href="#org86214c5">tf.boolean<sub>mask</sub></a></li>
<li><a href="#orgd83a9d4">tf.where</a></li>
<li><a href="#orgd139fc8">tf.scatter<sub>nd</sub></a></li>
<li><a href="#org94aece7">tf.meshgrid</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf39c541">activation function</a>
<ul>
<li><a href="#org76d1e1c">no activation</a></li>
<li><a href="#org52e7357">Sigmoid</a></li>
<li><a href="#org913dddc">ReLU</a></li>
<li><a href="#orgc0560b9">LeakyReLU</a></li>
<li><a href="#orgd2ecd24">Tanh</a></li>
<li><a href="#org109efa9">MSE</a></li>
<li><a href="#orga9f2ba1">inf entropy</a></li>
<li><a href="#org4176fba">softmax</a></li>
<li><a href="#org56c7e7f">cross entropy</a></li>
</ul>
</li>
<li><a href="#org3c874aa">Backpropagation</a>
<ul>
<li><a href="#org4cdb1fd">感知机</a></li>
<li><a href="#orgc1a2280">多层神经网络</a></li>
</ul>
</li>
<li><a href="#org1aade61">chapter 01</a></li>
<li><a href="#org4a22609">MNIST dataset</a></li>
<li><a href="#org2b617fd">Make<sub>moons</sub></a></li>
<li><a href="#org15d002d">Keras</a>
<ul>
<li><a href="#org85c17fb">tf.keras</a></li>
<li><a href="#org106b974">模型的保存和加载</a>
<ul>
<li><a href="#org26195f7">保存数值</a></li>
<li><a href="#org6732694">保存框架</a></li>
<li><a href="#orgb18a191">跨系统平台保存恢复</a></li>
</ul>
</li>
<li><a href="#org3128177">self-def</a></li>
</ul>
</li>
<li><a href="#org1dec6c9">regularation</a>
<ul>
<li><a href="#org8c17045">L0</a></li>
<li><a href="#org7770020">L1</a></li>
<li><a href="#org0f6a4bf">L2</a></li>
</ul>
</li>
<li><a href="#org4555ebc">Dropout</a></li>
<li><a href="#org542d182">Data Augmentation</a>
<ul>
<li><a href="#orga1bb446">resize</a></li>
<li><a href="#org035c0c7">rote</a></li>
<li><a href="#orgc854041">flip</a></li>
<li><a href="#org92f9bb2">crop</a></li>
</ul>
</li>
<li><a href="#org94b0034">convolution neural network</a></li>
<li><a href="#org0db8c95">Backlinks</a></li>
<li><a href="#orga429ff7">1 Backlinks</a>
<ul>
<li><a href="#org3698520">AI</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
tensorflow2手册的相关代码
</p>
<div id="outline-container-org6d37b5c" class="outline-2">
<h2 id="org6d37b5c">Check GPU</h2>
<div class="outline-text-2" id="text-org6d37b5c">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> tensorflow <span style="color: #4f97d7; font-weight: bold;">as</span> tf
<span style="color: #4f97d7; font-weight: bold;">if</span> (tf.test.is_gpu_available(cuda_only=<span style="color: #a45bad;">False</span>, min_cuda_compute_capability=<span style="color: #a45bad;">None</span>)==<span style="color: #a45bad;">True</span>):
    <span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">"using gpu"</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb4cd477" class="outline-2">
<h2 id="orgb4cd477">Tensorflow foundation</h2>
<div class="outline-text-2" id="text-orgb4cd477">
</div>
<div id="outline-container-orgcc04d4b" class="outline-3">
<h3 id="orgcc04d4b">数值类型</h3>
<div class="outline-text-3" id="text-orgcc04d4b">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-right" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<tbody>
<tr>
<td class="org-left">type</td>
<td class="org-right">diam</td>
<td class="org-left">shape</td>
<td class="org-left">example</td>
<td class="org-left">function</td>
</tr>

<tr>
<td class="org-left">Scalar</td>
<td class="org-right">0</td>
<td class="org-left">[]</td>
<td class="org-left">[]</td>
<td class="org-left">acc</td>
</tr>

<tr>
<td class="org-left">Vector</td>
<td class="org-right">1</td>
<td class="org-left">[n,]</td>
<td class="org-left">[1.0]</td>
<td class="org-left">bias (b)</td>
</tr>

<tr>
<td class="org-left">Matrix</td>
<td class="org-right">2</td>
<td class="org-left">[n, m]</td>
<td class="org-left">[[1,2],[3,4]]</td>
<td class="org-left">weight (W)</td>
</tr>

<tr>
<td class="org-left">Tensor</td>
<td class="org-right">&gt;2</td>
<td class="org-left">[n,m,p]</td>
<td class="org-left">[[[1],[1]],[[2],[2]]]</td>
<td class="org-left">input ( [n, h, w, 3]</td>
</tr>
</tbody>
</table>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #7590db;">a</span> = tf.constant(example)
tf.constant() &#21151;&#33021;&#31867;&#20284;&#20110;tf.convert_to_tensor()
<span style="color: #7590db;">b</span> = tf.constant(<span style="color: #2d9574;">'Hello Deep learning'</span>)
<span style="color: #7590db;">c</span> = tf.constant(<span style="color: #a45bad;">True</span>)
<span style="color: #7590db;">dtype</span>=tf.int16, int32, int64,tf.float16, tf.float32, tf.float64
tf.cast(a, tf.float64)
tf.Variable(a)&#21487;&#20197;&#28155;&#21152;a&#30340;&#21487;&#35757;&#32451;&#23646;&#24615;
tf.zeros([n,m])  tf.zeros_like(a)  == tf.zeros(a.shape)
tf.ones([n,m])   tf.ones_like(a)   == tf.ones(a.shape)
tf.fill([2,2],10)
tf.random.normal([2,2]) == tf.random.normal([2,2], mean=0, stddev=1)
tf.random.uniform(shape, minval=0,maxval=10,dtype=tf.float32)
tf.<span style="color: #4f97d7;">range</span>(10) == tf.<span style="color: #4f97d7;">range</span>(0,10, delta = 2)

</pre>
</div>
</div>
</div>
<div id="outline-container-org94b026c" class="outline-3">
<h3 id="org94b026c">Reference(,) and Segment(:)</h3>
<div class="outline-text-3" id="text-org94b026c">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #7590db;">x</span> = tf.random.normal([4,32,32,3])
x[2][1][0][1]  == x[2,1,0,1]

[start:end:step] <span style="color: #4f97d7; font-weight: bold;">for</span> each dimension.
x[1:3:2, 1:4:2, 2:4:2, 1:3:2]

</pre>
</div>
</div>
</div>

<div id="outline-container-org6b744f4" class="outline-3">
<h3 id="org6b744f4">改变视图</h3>
<div class="outline-text-3" id="text-org6b744f4">
<p>
x = tf.random.normal([4,32,32,3]) 的数据是整体贮存的，可以合法的
reshape. 从后往前合并，拆分。
</p>
</div>

<div id="outline-container-org5e5eb69" class="outline-4">
<h4 id="org5e5eb69">增加维度</h4>
<div class="outline-text-4" id="text-org5e5eb69">
<p>
增加前置维度
tf.expand<sub>dims</sub>(x, axis=0)
增加后置维度
tf.expand<sub>dims</sub>(x, axis=-1)
也可以是其他值，表示在相应的位置增加一个维度
</p>
</div>
</div>

<div id="outline-container-orgfdde96c" class="outline-4">
<h4 id="orgfdde96c">删除维度</h4>
<div class="outline-text-4" id="text-orgfdde96c">
<p>
删除前置
tf.squeeze(x, axis=0)
后置和其他位置一样，删除dia=1的维度
</p>
</div>
</div>
</div>

<div id="outline-container-org474747b" class="outline-3">
<h3 id="org474747b">交换维度</h3>
<div class="outline-text-3" id="text-org474747b">
<p>
这会改变数据的贮存顺序
x = tf.random.normal([2,32,32,3])
x = tf.transpose(x, perm=[0,3,1,2])
以前的维度下表变换为perm
</p>
</div>
</div>

<div id="outline-container-orgdb7cdae" class="outline-3">
<h3 id="orgdb7cdae">Broadcasting</h3>
</div>
<div id="outline-container-org58d2f9d" class="outline-3">
<h3 id="org58d2f9d">tile</h3>
<div class="outline-text-3" id="text-org58d2f9d">
<p>
x = tf.random.normal([4,32,32,3])
y = tf.tile(x,[2,3,3,1]) 对应维度各复制成原来的2，3，3，1倍。
</p>
</div>
</div>

<div id="outline-container-orgceea294" class="outline-3">
<h3 id="orgceea294">Concatenate &amp; Stack &amp; Split &amp; unstack</h3>
<div class="outline-text-3" id="text-orgceea294">
<p>
tf.concat([a,b],axis=0) 除了axis=0外的所有维度都应该一样
tf.stack([a,b],axis=0) a,b的所有维度应该都一样，插入的位置和
expand<sub>dims</sub>() 遵守相同规则
tf.split(x, num<sub>or</sub><sub>size</sub><sub>splits</sub>=10, axis=0) 拆分的维度不消失
tf.unstack(x, axis=0) 拆为步长为1           拆分的维度消失
</p>
</div>
</div>

<div id="outline-container-orgb57af20" class="outline-3">
<h3 id="orgb57af20">Statistik</h3>
<div class="outline-text-3" id="text-orgb57af20">
<p>
L1 Norm  \(||x_{1}|| = \sum_{i}|x_{i}|\)
tf.norm(x, ord=1)
L2 Norm  \(||x_{2}|| = \sqrt{\sum_{i}|x_{i}|^2 }\)
tf.norm(x,ord=2)
</p>

<p>
tf.reduce<sub>max</sub>(x, axis=0)
tf.reduce<sub>min</sub>()
tf.reduce<sub>mean</sub>()
tf.reduce<sub>sum</sub>()
不指明axis则是对全局求解
tf.argmax(x, axis) 
tf.argmin(x,axis) axis 轴的极值坐标
</p>

<div class="org-src-container">
<pre class="src src-python">
<span style="color: #7590db;">out</span> = tf.random.normal([100,10])
<span style="color: #7590db;">out</span> = tf.nn.softmax(out, axis=1)
<span style="color: #7590db;">pred</span> = tf.argmax(out, axis=1)
<span style="color: #7590db;">y</span> = tf.random.uniform([100],dtype=tf.int64,maxval=10)
<span style="color: #7590db;">out</span> = tf.equal(pred, y)
<span style="color: #7590db;">out</span> = tf.cast(out, dtype=tf.float32)
<span style="color: #7590db;">cor</span> = tf.reduce_sum(out)
</pre>
</div>
</div>
</div>

<div id="outline-container-org67784d8" class="outline-3">
<h3 id="org67784d8">Padding</h3>
<div class="outline-text-3" id="text-org67784d8">
<pre class="example">
x = tf.pad(x,[[0,2]]) []内是padding 填充的方案，每个[]表示一个维度
</pre>
</div>
</div>







<div id="outline-container-org8ed14de" class="outline-3">
<h3 id="org8ed14de">advance manipulation</h3>
<div class="outline-text-3" id="text-org8ed14de">
</div>
<div id="outline-container-org04e04d4" class="outline-4">
<h4 id="org04e04d4">tf.minimum</h4>
<div class="outline-text-4" id="text-org04e04d4">
<p>
tf.minimum(x, a) 最小a
tf.maximum(x, b) 最大b
tf.minimum(tf.maximum(x,2),7) == tf.clip<sub>by</sub><sub>value</sub>(x,2,7)
</p>
</div>
</div>

<div id="outline-container-org61dd24a" class="outline-4">
<h4 id="org61dd24a">tf.gather</h4>
<div class="outline-text-4" id="text-org61dd24a">
<p>
tf.gather(x, [0,2,4,5,7],axis =1) 抽取在axis=1上的[0,2,4,5,7]坐标的组
成数据，并可以重新定义组成数据的顺序
</p>
</div>
</div>
<div id="outline-container-org15b5d72" class="outline-4">
<h4 id="org15b5d72">tf.gather<sub>nd</sub></h4>
<div class="outline-text-4" id="text-org15b5d72">
<p>
tf.gather<sub>nd</sub>(x,[[1,1],[2,2],[3,3]]) 
后面根的[]说明了所有成员要操作的维度，
第一成员的第一维坐标为1，第二维坐标为1..
所有成员组成List
</p>
</div>
</div>
<div id="outline-container-org86214c5" class="outline-4">
<h4 id="org86214c5">tf.boolean<sub>mask</sub></h4>
<div class="outline-text-4" id="text-org86214c5">
<p>
tf.boolean<sub>mask</sub>(x, mask=[True, False, True, False],axis =0)
在axis=0的轴上，只有mask成员是True才会被选中，mask 长度等于axis=0 轴的
长度。
</p>
</div>
</div>
<div id="outline-container-orgd83a9d4" class="outline-4">
<h4 id="orgd83a9d4">tf.where</h4>
<div class="outline-text-4" id="text-orgd83a9d4">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #7590db;">a</span> = tf.ones([3,3])
<span style="color: #7590db;">b</span> = tf.zeros([3,3])
<span style="color: #7590db;">cond</span> = tf.constant([<span style="color: #a45bad;">True</span>,<span style="color: #a45bad;">False</span>,<span style="color: #a45bad;">False</span>],[<span style="color: #a45bad;">False</span>, <span style="color: #a45bad;">True</span>, <span style="color: #a45bad;">True</span>],[<span style="color: #a45bad;">False</span>, <span style="color: #a45bad;">False</span>, <span style="color: #a45bad;">False</span>])
<span style="color: #7590db;">c</span> = tf.where(cond, a,b)
</pre>
</div>
<p>
tf.where(cond) 返回所有值为True元素的下标
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #7590db;">x</span> = tf.random.normal([3.3])
<span style="color: #7590db;">mask</span> = x&gt;0
<span style="color: #7590db;">ind</span> = tf.where(mask)
<span style="color: #7590db;">a</span> = tf.gather_nd(x,ind)
</pre>
</div>
</div>
</div>
<div id="outline-container-orgd139fc8" class="outline-4">
<h4 id="orgd139fc8">tf.scatter<sub>nd</sub></h4>
<div class="outline-text-4" id="text-orgd139fc8">
<p>
在一个长度为8的空白向量（全为0）里，将updates按照indices的位置写入
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #7590db;">indices</span> = tf.constant([[4],[3],[2],[1]])
<span style="color: #7590db;">updates</span> = tf.constant([3,1,0,2])
tf.scatter_nd(indices, updates, [8])

</pre>
</div>
</div>
</div>

<div id="outline-container-org94aece7" class="outline-4">
<h4 id="org94aece7">tf.meshgrid</h4>
<div class="outline-text-4" id="text-org94aece7">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #7590db;">x</span> = tf.linspace(-8., 8, 100)   <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">-8&#21518;&#38754;&#30340;. &#19981;&#33021;&#30465;&#30053;</span>
<span style="color: #7590db;">y</span> = tf.linspace(-8., 8, 100)
<span style="color: #7590db;">x.shape</span> = 100
<span style="color: #7590db;">x</span>, <span style="color: #7590db;">y</span> = tf.meshgrid(x,y)
<span style="color: #7590db;">x.shape</span> = [100,100]
ax.contour3D(x.numpy(), y.numpy(), z.numpy(), 50)

</pre>
</div>
</div>
</div>
</div>
</div>


<div id="outline-container-orgf39c541" class="outline-2">
<h2 id="orgf39c541">activation function</h2>
<div class="outline-text-2" id="text-orgf39c541">
</div>
<div id="outline-container-org76d1e1c" class="outline-3">
<h3 id="org76d1e1c">no activation</h3>
<div class="outline-text-3" id="text-org76d1e1c">
<p>
输出为实数空间或某个区间， 连续变化。直接有输出值和真实值比较
</p>
</div>
</div>
<div id="outline-container-org52e7357" class="outline-3">
<h3 id="org52e7357">Sigmoid</h3>
<div class="outline-text-3" id="text-org52e7357">
<p>
\[ Sigmoid(x) = \frac{1}{1+e^{-x}}\]
</p>

<p>
导数：\[ \sigma'(x) = \sigma(x)(1-\sigma(x))\]
</p>
</div>
</div>

<div id="outline-container-org913dddc" class="outline-3">
<h3 id="org913dddc">ReLU</h3>
<div class="outline-text-3" id="text-org913dddc">
<p>
\[ Relu(x) = 
\begin{cases}
x&  x >=0 \\
0&  x < 0
\end{cases}\]
</p>

<p>
\[ Relu(x) = max(0,x)\]
</p>
</div>
</div>

<div id="outline-container-orgc0560b9" class="outline-3">
<h3 id="orgc0560b9">LeakyReLU</h3>
<div class="outline-text-3" id="text-orgc0560b9">
<p>
\[ LeakyReLU(x) = 
\begin{cases}
x& x >=0 \\
px& x <0, 0<p<<1
\end{cases}\]
</p>
</div>
</div>

<div id="outline-container-orgd2ecd24" class="outline-3">
<h3 id="orgd2ecd24">Tanh</h3>
<div class="outline-text-3" id="text-orgd2ecd24">
<p>
\[ tanh(x) = \frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}\]
\[ tanh(x) = 2.sigmoid(2x)-1\]
导数：\[\tanh'(x) = 1- \tanh^{2}(x)\]
</p>
</div>
</div>

<div id="outline-container-org109efa9" class="outline-3">
<h3 id="org109efa9">MSE</h3>
<div class="outline-text-3" id="text-org109efa9">
<p>
\[ \mathcal{L} = MSE(y, o) =
\frac{1}{d_{out}}\sum_{i=1}^{d_{out}}(y_{i}-o^{i})^{2}\]
导数 ：\[ \frac{\partial \mathcal{L}}{\partial o_{i}}= (o_{i}-y_{i})\]
</p>
</div>
</div>

<div id="outline-container-orga9f2ba1" class="outline-3">
<h3 id="orga9f2ba1">inf entropy</h3>
<div class="outline-text-3" id="text-orga9f2ba1">
<p>
\[ H(p) = -\sum_{i}P(i)\log_{2}^{P_{i}}\]
</p>
</div>
</div>
<div id="outline-container-org4176fba" class="outline-3">
<h3 id="org4176fba">softmax</h3>
<div class="outline-text-3" id="text-org4176fba">
<p>
\[ p_{z_{i}} = \frac{e^{z_{i}}}{\sum_{j}e^{z_{j}}}\]
所有种类的概率之和为1
导数:
\[ \frac{ \partial p_{z_{i}}}{\partial z_{j}} = 
\begin{cases}
p_{i}(1-p_{j}) &  if i =j \\
-p_{i}p_{j}    & if \neq j
\end{cases}\]
</p>
</div>
</div>

<div id="outline-container-org56c7e7f" class="outline-3">
<h3 id="org56c7e7f">cross entropy</h3>
<div class="outline-text-3" id="text-org56c7e7f">
<p>
在计算交叉熵时， 一般是和 softmax 函数一起使用的
\[ H(p||q) = -\sum_{i} p(i) \log_{2}^{q_{i}}\]
\[H(p||q) = H(p) + D_{KL}(p||q)\]
</p>

<p>
for One-hot coding
\[ H(p||q) = D_{KL}(p||q) = \sum_{i}y_{i}log(\frac{y_{j}}{o_{j}}) = 
1 \cdot \log\frac{1}{o_{i}} + \sum_{j!=i}0 \cdot \log \frac{0}{o_{j}}
= -\log o_{i}\]
o<sub>i</sub> 为1 时，预测正确，交叉熵为0。
导数：
\[ \mathcal{L} = -\sum_{k}y_{k}\log(p_{k})\]
\[\begin{aligned}
 \frac{\partial \mathcal{L}}{\partial z_{i}} & =
-\sum_{k} y_{k} \frac{\partial \log(p_{k})}{\partial z_{i}} \\
&= -\sum_{k} y_{k} \frac{\partial \log(p_{k})}{\partial p_{k}} \cdot
\frac{\partial p_{k}}{\partial z_{i}} \\
&= -\sum_{k} y_{k} \frac{1}{\partial p_{k}} \cdot
\frac{\partial p_{k}}{\partial z_{i}} \\
\end{aligned}
\]
</p>

<p>
用上面 softmax 的导数结果，分为k=i 和k!=i两种情况
\[ \frac{\partial \mathcal{L}}{z_{i}}=p_{i}-y_{i}\]
</p>
</div>
</div>
</div>

<div id="outline-container-org3c874aa" class="outline-2">
<h2 id="org3c874aa">Backpropagation</h2>
<div class="outline-text-2" id="text-org3c874aa">
</div>
<div id="outline-container-org4cdb1fd" class="outline-3">
<h3 id="org4cdb1fd">感知机</h3>
<div class="outline-text-3" id="text-org4cdb1fd">
<p>
对x的向后更正，\(x^{'}= x - \eta \cdot \frac{dy}{dx}\).
对于感知机的传递功能，\(y = w^{T}x + b\).
由于感知机没有激活函数，所以直接对\[\mathcal{L} = \frac{1}{n}
\sum^{n}_{i=1}(w\cdot x^{i} +b -y^{i})^{2}\].
\[ \frac{\partial \mathcal{L}}{\partial w} = \frac{2}{n}
\sum^{n}_{i=1}(wx^{i}+b-y^{i})x^{i}\]
\[ \frac{\partial \mathcal{L}}{\partial b}= \frac{2}{n}\sum^{n}_{i=1}(wx^{i}+b -y^{i})\]
</p>
</div>
</div>

<div id="outline-container-orgc1a2280" class="outline-3">
<h3 id="orgc1a2280">多层神经网络</h3>
<div class="outline-text-3" id="text-orgc1a2280">
<p>
而对于多层神经网络，\(z = w^{T}x + b\), \(\frac{\partial z}{\partial w} =x\),  \(\frac{\partial z}{\partial b} = 1\).
每层之间具有激活函数, \(\sigma(z) = \frac{1}{1-e^{-z}}\),\(\frac{\partial \sigma(x)}{\partial x} = \sigma (1-\sigma)\).
损失函数, \(\mathcal{L} = \frac{1}{2}(\sigma - y^{i})^{2}\), \[\frac{\partial \mathcal{L}}{\partial \sigma} = (\sigma -y^{i})\]
</p>


<p>
\[\frac{\partial \mathcal{L}}{\partial w} = \frac{\partial
\mathcal{L}}{\partial \sigma} \cdot \frac{\partial \sigma }{\partial z} \cdot
\frac{\partial z}{\partial w}\]
</p>


<p>
\(\frac{\partial \mathcal{L}}{\partial w} = (\sigma -
y)\sigma(1-\sigma) \cdot x\)
</p>

<p>
\[\frac{\partial \mathcal{L}}{\partial b} = \frac{\partial
\mathcal{L}}{\partial \sigma} \cdot \frac{\partial \sigma }{\partial z} \cdot
\frac{\partial z}{\partial b}\]
</p>

<p>
\(\frac{\partial  \mathcal{L}}{\partial b} = (\sigma -
y)\sigma(1-\sigma)\)
</p>

<p>
如果对于多层神经网络，则需要逐层计算，其中\(\frac{\partial
\mathcal{L}}{\partial w}\) 中的w就是相应层的权重，由最后的
L逐步回推到w。
</p>
</div>
</div>
</div>

<div id="outline-container-org1aade61" class="outline-2">
<h2 id="org1aade61">chapter 01</h2>
<div class="outline-text-2" id="text-org1aade61">
<p>
一个很简单的例子，用tf来求某个函数的导数
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> tensorflow <span style="color: #4f97d7; font-weight: bold;">as</span> tf
<span style="color: #7590db;">a</span> = tf.constant(1.)
<span style="color: #7590db;">b</span> = tf.constant(2.)
<span style="color: #7590db;">c</span> = tf.constant(3.)
<span style="color: #7590db;">w</span> = tf.constant(4.)

<span style="color: #4f97d7; font-weight: bold;">with</span> tf.GradientTape() <span style="color: #4f97d7; font-weight: bold;">as</span> tape:
    tape.watch([w])
    <span style="color: #7590db;">y</span> = a*w**2 + b*w + c
[dy_dw] = tape.gradient(y, [w])
<span style="color: #4f97d7; font-weight: bold;">print</span>(dy_dw)

</pre>
</div>


<p>
检测cpu和gpu运行时的时间对比
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> tensorflow <span style="color: #4f97d7; font-weight: bold;">as</span> tf
<span style="color: #4f97d7; font-weight: bold;">import</span> timeit

<span style="color: #7590db;">n</span> = 10000000
<span style="color: #4f97d7; font-weight: bold;">with</span> tf.device(<span style="color: #2d9574;">'/cpu:0'</span>):
    <span style="color: #7590db;">cpu_a</span> = tf.random.normal([1, n])
    <span style="color: #7590db;">cpu_b</span> = tf.random.normal([n, 1])

<span style="color: #4f97d7; font-weight: bold;">with</span> tf.device(<span style="color: #2d9574;">'/gpu:0'</span>):
    <span style="color: #7590db;">gpu_a</span> = tf.random.normal([1, n])
    <span style="color: #7590db;">gpu_b</span> = tf.random.normal([n, 1])

<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">cpu_run</span>():
    <span style="color: #4f97d7; font-weight: bold;">with</span> tf.device(<span style="color: #2d9574;">'/cpu:0'</span>):
        <span style="color: #7590db;">c</span> = tf.matmul(cpu_a, cpu_b)
    <span style="color: #4f97d7; font-weight: bold;">return</span> c

<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">gpu_run</span>():
    <span style="color: #4f97d7; font-weight: bold;">with</span> tf.device(<span style="color: #2d9574;">'/gpu:0'</span>):
        <span style="color: #7590db;">c</span> = tf.matmul(gpu_a, cpu_b)
    <span style="color: #4f97d7; font-weight: bold;">return</span> c

<span style="color: #7590db;">cpu_time</span> = timeit.timeit(cpu_run, number=10)
<span style="color: #7590db;">gpu_time</span> = timeit.timeit(cpu_run, number=10)
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">'run time: '</span>, cpu_time, gpu_time)



</pre>
</div>

<p>
不用tensorflow的API，使用纯函数来实现神经网络训练的例子
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> numpy <span style="color: #4f97d7; font-weight: bold;">as</span> np
<span style="color: #7590db;">data</span> = []
<span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(100):
    <span style="color: #7590db;">x</span> = np.random.uniform(-10., 10)
    <span style="color: #7590db;">y</span> = 1.477*x + 0.089 + np.random.normal(0., 0.01)
    data.append([x, y])
<span style="color: #7590db;">data</span> = np.array(data)


<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">mse</span>(b, w, points):
    <span style="color: #7590db;">totalError</span> = 0
    <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(0, <span style="color: #4f97d7;">len</span>(points)):
        <span style="color: #7590db;">x</span> = points[i, 0]
        <span style="color: #7590db;">y</span> = points[i, 1]
        <span style="color: #7590db;">totalError</span> += (y-(w*x+b))**2
    <span style="color: #4f97d7; font-weight: bold;">return</span> totalError/<span style="color: #4f97d7;">float</span>(<span style="color: #4f97d7;">len</span>(points))


<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">step_gradient</span>(b_current, w_current, points, lr):
    <span style="color: #7590db;">b_gradient</span> = 0
    <span style="color: #7590db;">w_gradient</span> = 0
    <span style="color: #7590db;">M</span> = <span style="color: #4f97d7;">float</span>(<span style="color: #4f97d7;">len</span>(points))
    <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(0, <span style="color: #4f97d7;">len</span>(points)):
        <span style="color: #7590db;">x</span> = points[i, 0]
        <span style="color: #7590db;">y</span> = points[i, 1]
        <span style="color: #7590db;">b_gradient</span> += (2/M)*((w_current*x+b_current)-y)
        <span style="color: #7590db;">w_gradient</span> += (2/M)*x*((w_current*x + b_current)-y)
    <span style="color: #7590db;">new_b</span> = b_current - (lr*b_gradient)
    <span style="color: #7590db;">new_w</span> = w_current - (lr*w_gradient)
    <span style="color: #4f97d7; font-weight: bold;">return</span> [new_b, new_w]


<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">gradient_descent</span>(points, staring_b, staring_w, lr, num_iterations):
    <span style="color: #7590db;">b</span> = staring_b
    <span style="color: #7590db;">w</span> = staring_w
    <span style="color: #4f97d7; font-weight: bold;">for</span> step <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(num_iterations):
        <span style="color: #7590db;">b</span>, <span style="color: #7590db;">w</span> = step_gradient(b, w, np.array(points), lr)
        <span style="color: #7590db;">loss</span> = mse(b, w, points)
        <span style="color: #4f97d7; font-weight: bold;">if</span> step % 5000  == 0:
            <span style="color: #4f97d7; font-weight: bold;">print</span>(f<span style="color: #2d9574;">"iterations:{step}, loss :{loss}, w:{w}, b:{b}"</span>)
    <span style="color: #4f97d7; font-weight: bold;">return</span> [b, w]


<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">main</span>():
    <span style="color: #7590db;">lr</span> = 0.001
    <span style="color: #7590db;">initial_b</span> = 0
    <span style="color: #7590db;">initial_w</span> = 0
    <span style="color: #7590db;">num_iterations</span> = 100000
    [b, w] = gradient_descent(data, initial_b, initial_w, lr, num_iterations)
    <span style="color: #7590db;">loss</span> = mse(b, w, data)
    <span style="color: #4f97d7; font-weight: bold;">print</span>(f<span style="color: #2d9574;">"Final loss :{loss}, w:{w}, b:{b}"</span>)


<span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">if __name__ ==' __main__':</span>
main()


</pre>
</div>
</div>
</div>

<div id="outline-container-org4a22609" class="outline-2">
<h2 id="org4a22609">MNIST dataset</h2>
<div class="outline-text-2" id="text-org4a22609">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> tensorflow <span style="color: #4f97d7; font-weight: bold;">as</span> tf
<span style="color: #4f97d7; font-weight: bold;">from</span> tensorflow <span style="color: #4f97d7; font-weight: bold;">import</span> keras
<span style="color: #4f97d7; font-weight: bold;">from</span> tensorflow.keras <span style="color: #4f97d7; font-weight: bold;">import</span> layers, optimizers, datasets
<span style="color: #7590db;">w1</span> = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))
<span style="color: #7590db;">b1</span> = tf.Variable(tf.zeros([256]))
<span style="color: #7590db;">w2</span> = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))
<span style="color: #7590db;">b2</span> = tf.Variable(tf.zeros([128]))
<span style="color: #7590db;">w3</span> = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))
<span style="color: #7590db;">b3</span> = tf.Variable(tf.zeros([10]))
(x,y),(x_val, y_val)=datasets.mnist.load_data()
<span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">'x:'</span>,x.shape, <span style="color: #2d9574;">'y:'</span>, y.shape,<span style="color: #2d9574;">'x test:'</span>, x_val.shape, <span style="color: #2d9574;">'y test:'</span>, y_val)
<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">preprocess</span>(x, y):
    <span style="color: #7590db;">x</span> = tf.cast(x, dtype = tf.float32)/255.
    <span style="color: #7590db;">x</span> = tf.reshape(x, [-1,28*28])
    <span style="color: #7590db;">y</span> = tf.cast(y,dtype=tf.int32)
    <span style="color: #7590db;">y</span> = tf.one_hot(y, depth=10)
    <span style="color: #4f97d7; font-weight: bold;">return</span> x,y
<span style="color: #7590db;">train_db</span> = tf.data.Dataset.from_tensor_slices((x,y))  <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">&#26500;&#24314;Dataset &#23545;&#35937;</span>
<span style="color: #7590db;">train_db</span> = train_db.shuffle(10000)                    <span style="color: #2aa1ae; background-color: #292e34;"># </span><span style="color: #2aa1ae; background-color: #292e34;">&#25171;&#25955;&#26679;&#26412;&#39034;&#24207;</span>
<span style="color: #7590db;">train_db</span> = train_db.batch(128)                        <span style="color: #2aa1ae; background-color: #292e34;">#</span><span style="color: #2aa1ae; background-color: #292e34;">&#25209;&#35757;&#32451;</span>
<span style="color: #7590db;">train_db</span> = train_db.<span style="color: #4f97d7;">map</span>(preprocess)
<span style="color: #7590db;">test_db</span> = tf.data.Dataset.from_tensor_slices((x_val, y_val))
<span style="color: #7590db;">test_db</span> = test_db.shuffle(1000)
<span style="color: #7590db;">test_db</span> = test_db.batch(128)
<span style="color: #7590db;">test_db</span> = test_db.<span style="color: #4f97d7;">map</span>(preprocess)
<span style="color: #7590db;">lr</span> = 0.001
<span style="color: #4f97d7; font-weight: bold;">for</span> epoch <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(8):
    <span style="color: #4f97d7; font-weight: bold;">for</span> step, (x,y) <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">enumerate</span>(train_db):
        <span style="color: #4f97d7; font-weight: bold;">with</span> tf.GradientTape() <span style="color: #4f97d7; font-weight: bold;">as</span> tape:
            <span style="color: #7590db;">h1</span> = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])
            <span style="color: #7590db;">h1</span> = tf.nn.relu(h1)
            <span style="color: #7590db;">h2</span> = h1@w2 + b2
            <span style="color: #7590db;">h2</span> = tf.nn.relu(h2)
            <span style="color: #7590db;">out</span> = h2@w3 + b3
            <span style="color: #7590db;">loss</span> = tf.square(y - out)
            <span style="color: #7590db;">loss</span> = tf.reduce_mean(loss)
            <span style="color: #7590db;">grads</span> = tape.gradient(loss, [w1,b1,w2,b2,w3,b3])
            w1.assign_sub(lr *grads[0])
            b1.assign_sub(lr * grads[1])
            w2.assign_sub(lr *grads[2])
            b2.assign_sub(lr * grads[3])
            w3.assign_sub(lr *grads[4])
            b3.assign_sub(lr * grads[5])
<span style="color: #4f97d7; font-weight: bold;">for</span> x, y <span style="color: #4f97d7; font-weight: bold;">in</span> test_db:
    <span style="color: #7590db;">h1</span> = x@w1 + b1
    <span style="color: #7590db;">h1</span> = tf.nn.relu(h1)
    <span style="color: #7590db;">h2</span> = h1@w2 + b2
    <span style="color: #7590db;">h2</span> = tf.nn.relu(h2)
    <span style="color: #7590db;">out</span> = h2@w3 + b3
    <span style="color: #7590db;">pred</span> = tf.argmax(out,axis=1)
    <span style="color: #7590db;">y</span> = tf.argmax(y, axis=1)
    <span style="color: #7590db;">correct</span> = tf.equal(pred, y)
    <span style="color: #7590db;">total_correct</span> +=tf.reduce_sum(tf.cast(correct,dty=tf.int32)).numpy()



</pre>
</div>
</div>
</div>

<div id="outline-container-org2b617fd" class="outline-2">
<h2 id="org2b617fd">Make<sub>moons</sub></h2>
<div class="outline-text-2" id="text-org2b617fd">
<p>
all import 
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> seaborn <span style="color: #4f97d7; font-weight: bold;">as</span> sns
<span style="color: #4f97d7; font-weight: bold;">import</span> matplotlib.pyplot <span style="color: #4f97d7; font-weight: bold;">as</span> plt
</pre>
</div>


<p>
generate the data
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">from</span> sklearn.datasets <span style="color: #4f97d7; font-weight: bold;">import</span> make_moons
<span style="color: #4f97d7; font-weight: bold;">from</span> sklearn.model_selection <span style="color: #4f97d7; font-weight: bold;">import</span> train_test_split
<span style="color: #7590db;">N_samples</span> = 2000
<span style="color: #7590db;">Test_size</span> = 0.3
<span style="color: #7590db;">X</span>, <span style="color: #7590db;">y</span> = make_moons(n_samples = N_samples, noise = 0.2, random_state=100)
<span style="color: #7590db;">X_train</span>, <span style="color: #7590db;">X_test</span>, <span style="color: #7590db;">y_train</span>, <span style="color: #7590db;">y_test</span> = train_test_split(X, y,test_size = Test_size, random_state = 42)
<span style="color: #4f97d7; font-weight: bold;">print</span>(X.shape, y.shape)
<span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">make_plot</span>(X, y, plot_name, file_name=<span style="color: #a45bad;">None</span>, XX=<span style="color: #a45bad;">None</span>, YY=<span style="color: #a45bad;">None</span>, preds=<span style="color: #a45bad;">None</span>,dark=<span style="color: #a45bad;">False</span>):
    <span style="color: #4f97d7; font-weight: bold;">if</span>(dark):
        plt.style.use(<span style="color: #2d9574;">'dark_background'</span>)
    <span style="color: #4f97d7; font-weight: bold;">else</span>:
        sns.set_style(<span style="color: #2d9574;">"whitegrid"</span>)
    plt.figure(figsize=(16,12))
    <span style="color: #7590db;">axes</span> = plt.gca()
    axes.<span style="color: #4f97d7;">set</span>(xlabel=<span style="color: #2d9574;">"$x_1$"</span>, ylabel=<span style="color: #2d9574;">"$x_2$"</span>)
    plt.title(plot_name,fontsize=30)
    plt.subplots_adjust(left=0.20)
    plt.subplots_adjust(right=0.8)
    <span style="color: #4f97d7; font-weight: bold;">if</span>(XX <span style="color: #4f97d7; font-weight: bold;">is</span> <span style="color: #4f97d7; font-weight: bold;">not</span> <span style="color: #a45bad;">None</span> <span style="color: #4f97d7; font-weight: bold;">and</span> YY <span style="color: #4f97d7; font-weight: bold;">is</span> <span style="color: #4f97d7; font-weight: bold;">not</span> <span style="color: #a45bad;">None</span> <span style="color: #4f97d7; font-weight: bold;">and</span> preds <span style="color: #4f97d7; font-weight: bold;">is</span> <span style="color: #4f97d7; font-weight: bold;">not</span> <span style="color: #a45bad;">None</span>):
        plt.contourf(XX,YY,preds.reshape(XX.shape), 25, alpha=1,cmap = cm.Spectral)
        plt.contour(XX,YY, preds.reshape(XX.shape), levels=[.5],cmap=<span style="color: #2d9574;">"Greys"</span>, vmin=0,vmax=0.6)
        plt.scatter(X[:,0],X[:,1],c=y.ravel(), s=40, cmap=plt.cm.Spectral,edgecolors=<span style="color: #2d9574;">'none'</span>)
        plt.savefig(<span style="color: #2d9574;">'data.svg'</span>)
        plt.close()
make_plot(X,y,<span style="color: #a45bad;">None</span>,<span style="color: #2d9574;">"Classification Dataset Visualization"</span>)
</pre>
</div>


<p>
generate the  signal Layer class
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">class</span> <span style="color: #ce537a; font-weight: bold;">Layer</span>:
    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">__init__</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>, n_input, n_neurons,activation=<span style="color: #a45bad;">None</span>, weight=<span style="color: #a45bad;">None</span>,bias=<span style="color: #a45bad;">None</span>):
        <span style="color: #4f97d7; font-weight: bold;">self</span>.weight = weight <span style="color: #4f97d7; font-weight: bold;">if</span> weight <span style="color: #4f97d7; font-weight: bold;">is</span> <span style="color: #4f97d7; font-weight: bold;">not</span> <span style="color: #a45bad;">None</span> <span style="color: #4f97d7; font-weight: bold;">else</span> np.random.randn(n_input,n_neurons)*np.sqrt(1/n_neurons)
        <span style="color: #4f97d7; font-weight: bold;">self</span>.bias = bias <span style="color: #4f97d7; font-weight: bold;">if</span> bias <span style="color: #4f97d7; font-weight: bold;">is</span> <span style="color: #4f97d7; font-weight: bold;">not</span> <span style="color: #a45bad;">None</span> <span style="color: #4f97d7; font-weight: bold;">else</span> np.random.rand(n_neurons)*0.1
        <span style="color: #4f97d7; font-weight: bold;">self</span>.activation = activation
        <span style="color: #4f97d7; font-weight: bold;">self</span>.last_activation = <span style="color: #a45bad;">None</span>
        <span style="color: #4f97d7; font-weight: bold;">self</span>.error = <span style="color: #a45bad;">None</span>
        <span style="color: #4f97d7; font-weight: bold;">self</span>.delta = <span style="color: #a45bad;">None</span>
    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">activate</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>,x):
        <span style="color: #7590db;">r</span> = np.dot(x, <span style="color: #4f97d7; font-weight: bold;">self</span>.weight)+<span style="color: #4f97d7; font-weight: bold;">self</span>.bias
        <span style="color: #4f97d7; font-weight: bold;">self</span>.last_activation = <span style="color: #4f97d7; font-weight: bold;">self</span>._apply_activation(r)
        <span style="color: #4f97d7; font-weight: bold;">return</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.last_activation
    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">_apply_activation</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>, r):
        <span style="color: #4f97d7; font-weight: bold;">if</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation <span style="color: #4f97d7; font-weight: bold;">is</span> <span style="color: #a45bad;">None</span>:
            <span style="color: #4f97d7; font-weight: bold;">return</span> r
        <span style="color: #4f97d7; font-weight: bold;">elif</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation == <span style="color: #2d9574;">'relu'</span>:
            <span style="color: #4f97d7; font-weight: bold;">return</span> np.maximum(r,0)
        <span style="color: #4f97d7; font-weight: bold;">elif</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation == <span style="color: #2d9574;">'tanh'</span>:
            <span style="color: #4f97d7; font-weight: bold;">return</span> np.tanh(r)
        <span style="color: #4f97d7; font-weight: bold;">elif</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation == <span style="color: #2d9574;">'sigmoid'</span>:
            <span style="color: #4f97d7; font-weight: bold;">return</span> 1/(1+np.exp(-r))
        <span style="color: #4f97d7; font-weight: bold;">return</span> r
    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">apply_activation_derivative</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>, r):
        <span style="color: #4f97d7; font-weight: bold;">if</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation <span style="color: #4f97d7; font-weight: bold;">is</span> <span style="color: #a45bad;">None</span>:
            <span style="color: #4f97d7; font-weight: bold;">return</span> np.ones_like(r)
        <span style="color: #4f97d7; font-weight: bold;">elif</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation == <span style="color: #2d9574;">'relu'</span>:
            <span style="color: #7590db;">grad</span> = np.array(r, copy=<span style="color: #a45bad;">True</span>)
            <span style="color: #7590db;">grad</span>[r&gt;0] = 1.
            <span style="color: #7590db;">grad</span>[r&lt;=0] =0.
            <span style="color: #4f97d7; font-weight: bold;">return</span> grad
        <span style="color: #4f97d7; font-weight: bold;">elif</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation == <span style="color: #2d9574;">'tanh'</span>:
            <span style="color: #4f97d7; font-weight: bold;">return</span> 1-r**2
        <span style="color: #4f97d7; font-weight: bold;">elif</span> <span style="color: #4f97d7; font-weight: bold;">self</span>.activation == <span style="color: #2d9574;">'sigmoid'</span>:
            <span style="color: #4f97d7; font-weight: bold;">return</span> r*(1-r)
        <span style="color: #4f97d7; font-weight: bold;">return</span> r

</pre>
</div>

<p>
generate the multi Layers Class NeuralNetwork
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">class</span> <span style="color: #ce537a; font-weight: bold;">NeuralNetwork</span>:
    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">__init__</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>):
        <span style="color: #4f97d7; font-weight: bold;">self</span>._layers = []
    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">add_layer</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>, layer):
        <span style="color: #4f97d7; font-weight: bold;">self</span>._layers.append(layer)
    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">feed_forward</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>, X):
        <span style="color: #4f97d7; font-weight: bold;">for</span> layer <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7; font-weight: bold;">self</span>._layers:
            <span style="color: #7590db;">X</span> = layer.activate(X)
        <span style="color: #4f97d7; font-weight: bold;">return</span> X

    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">backpropagation</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>, X, y,learning_rate):
        <span style="color: #7590db;">output</span> = <span style="color: #4f97d7; font-weight: bold;">self</span>.feed_forward(X)
        <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">reversed</span>(<span style="color: #4f97d7;">range</span>(<span style="color: #4f97d7;">len</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>._layers))):
            <span style="color: #7590db;">layer</span> = <span style="color: #4f97d7; font-weight: bold;">self</span>._layers[i]
            <span style="color: #4f97d7; font-weight: bold;">if</span> layer == <span style="color: #4f97d7; font-weight: bold;">self</span>._layers[-1]:
                <span style="color: #7590db;">layer.error</span> = y-output
                <span style="color: #7590db;">layer.delta</span> = layer.error*layer.apply_activation_derivative(output)
            <span style="color: #4f97d7; font-weight: bold;">else</span>:
                <span style="color: #7590db;">next_layer</span> = <span style="color: #4f97d7; font-weight: bold;">self</span>._layers[i+1]
                <span style="color: #7590db;">layer.error</span> = np.dot(next_layer.weights, next_layer.delta)
                <span style="color: #7590db;">layer.delta</span> = layer.error*layer.apply_activation_derivative(layer.last_activation)

        <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(<span style="color: #4f97d7;">len</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>._layers)):
            <span style="color: #7590db;">layer</span> = <span style="color: #4f97d7; font-weight: bold;">self</span>._layers[i]
            <span style="color: #7590db;">o_i</span> = np.atleast_2d(X <span style="color: #4f97d7; font-weight: bold;">if</span> i == 0 <span style="color: #4f97d7; font-weight: bold;">else</span>  <span style="color: #4f97d7; font-weight: bold;">self</span>._layers[i-1].last_activation)
            <span style="color: #7590db;">layer.weights</span> += layer.delta*o_i.T*learning_rate


    <span style="color: #4f97d7; font-weight: bold;">def</span> <span style="color: #bc6ec5; font-weight: bold;">train</span>(<span style="color: #4f97d7; font-weight: bold;">self</span>, X_train, X_test, y_train, y_test, learning_rate, max_epochs):
        <span style="color: #7590db;">y_onehot</span> = np.zeros((y_train.shape[0],2))
        y_onehot[np.arange(y_train.shape[0]),y_train] =1
        <span style="color: #7590db;">mses</span> = []
        <span style="color: #4f97d7; font-weight: bold;">for</span> i <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(max_epochs):
            <span style="color: #4f97d7; font-weight: bold;">for</span> j <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(<span style="color: #4f97d7;">len</span>(X_train)):
                <span style="color: #4f97d7; font-weight: bold;">self</span>.backpropagation(X_train[j], y_onehot[j], learning_rate)
            <span style="color: #4f97d7; font-weight: bold;">if</span> i%10 == 0:
                <span style="color: #7590db;">mse</span> = np.mean(np.square(y_onehot - <span style="color: #4f97d7; font-weight: bold;">self</span>.feed_forward(X_train)))
                mses.<span style="color: #4f97d7;">apply</span>(mse)
                <span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">'Epoch : #%s, MSE: %f'</span> %(i, <span style="color: #4f97d7;">float</span>(mse)))
                <span style="color: #4f97d7; font-weight: bold;">print</span>(<span style="color: #2d9574;">'Accuracy: %.2f%%'</span> %(<span style="color: #4f97d7; font-weight: bold;">self</span>.accuracy(<span style="color: #4f97d7; font-weight: bold;">self</span>.predict(X_test),y_test.flatten())*100))
        <span style="color: #4f97d7; font-weight: bold;">return</span> mses


</pre>
</div>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #7590db;">nn</span> = Neuralnetwork()
nn.add_layer(Layer (2, 25, <span style="color: #2d9574;">'sigmoid'</span>))
nn.add_layer(Layer(25, 50, <span style="color: #2d9574;">'sigmoid'</span>))
nn.add_layer(Layer(50, 25, <span style="color: #2d9574;">'sigmoid'</span>))
nn.add_layer(Layer(25, 2, <span style="color: #2d9574;">'sigmoid'</span>))
nn.backpropagation(X_train,y_train,0.001)
nn.train(X_train, X_test, y_train, y_test, 0.001,20)


</pre>
</div>

<p>
different Layers
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">for</span> n <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(5):
    <span style="color: #7590db;">model</span> = Sequential()
    model.add(Dense(8,input_dim=2,activation=<span style="color: #2d9574;">'relu'</span>))
    <span style="color: #4f97d7; font-weight: bold;">for</span> _ <span style="color: #4f97d7; font-weight: bold;">in</span> <span style="color: #4f97d7;">range</span>(n):
        model.add(Dense(32,activation=<span style="color: #2d9574;">'relu'</span>))
    model.add(Dense(1,activation=<span style="color: #2d9574;">'sigmoid'</span>))
    model.<span style="color: #4f97d7;">compile</span>(loss=<span style="color: #2d9574;">'binary_crossentropy'</span>,optimizer=<span style="color: #2d9574;">'adam'</span>,metrics=[<span style="color: #2d9574;">'accuracy'</span>])
    <span style="color: #7590db;">history</span> = model.fit(X_train,y_train,epochs = 20, verbose=1)
    <span style="color: #7590db;">preds</span> = model.predict_classes(np.c_[XX.ravel(), YY_ravel()])
    <span style="color: #7590db;">title</span> = <span style="color: #2d9574;">"&#32593;&#32476;&#23618;&#25968;({})"</span>.<span style="color: #4f97d7;">format</span>(n)
    <span style="color: #4f97d7;">file</span> = <span style="color: #2d9574;">"&#32593;&#32476;&#23481;&#37327; %f.png"</span> %(2+n*1)
    make_plot(X_train,y_train, title,<span style="color: #4f97d7;">file</span>,XX,YY,preds)


</pre>
</div>
</div>
</div>

<div id="outline-container-org15d002d" class="outline-2">
<h2 id="org15d002d">Keras</h2>
<div class="outline-text-2" id="text-org15d002d">
</div>
<div id="outline-container-org85c17fb" class="outline-3">
<h3 id="org85c17fb">tf.keras</h3>
<div class="outline-text-3" id="text-org85c17fb">
<div class="org-src-container">
<pre class="src src-python"><span style="color: #4f97d7; font-weight: bold;">import</span> tensorflow <span style="color: #4f97d7; font-weight: bold;">as</span> tf
<span style="color: #4f97d7; font-weight: bold;">from</span> tensorflow <span style="color: #4f97d7; font-weight: bold;">import</span> keras
<span style="color: #4f97d7; font-weight: bold;">from</span> tensorflow.keras <span style="color: #4f97d7; font-weight: bold;">import</span> layers

<span style="color: #7590db;">x</span> = tf.constant([2., 1., 0.1])
<span style="color: #4f97d7; font-weight: bold;">print</span>(tf.keras.layers.Softmax(axis=-1)(x))
<span style="color: #4f97d7; font-weight: bold;">print</span>(tf.nn.softmax(x))

</pre>
</div>

<p>
tf.keras.Model 是tf.keras.Sequential的父类(网络类）
Sequential类还有方法：
Sequential.compile()
Sequential.fit()
Sequential.predict()
</p>

<p>
tf.keras.layers.Layer 是网络层类的父类（网络层类）
</p>
</div>
</div>

<div id="outline-container-org106b974" class="outline-3">
<h3 id="org106b974">模型的保存和加载</h3>
<div class="outline-text-3" id="text-org106b974">
</div>
<div id="outline-container-org26195f7" class="outline-4">
<h4 id="org26195f7">保存数值</h4>
<div class="outline-text-4" id="text-org26195f7">
<p>
Sequential.save<sub>weights</sub>('weights.ckpt')
重建了一样的网络后，重新加载
Sequential.load<sub>weights</sub>('weights.ckpt')
</p>
</div>
</div>
<div id="outline-container-org6732694" class="outline-4">
<h4 id="org6732694">保存框架</h4>
<div class="outline-text-4" id="text-org6732694">
<p>
tf.keras.Sequential.save('model.h5')
不需要重构模型，可以直接生成保存的模型
network = tf.keras.models.load<sub>model</sub>('model.h5')
</p>
</div>
</div>
<div id="outline-container-orgb18a191" class="outline-4">
<h4 id="orgb18a191">跨系统平台保存恢复</h4>
<div class="outline-text-4" id="text-orgb18a191">
<p>
tf.saved<sub>model.save</sub>(network, 'model-savedmodel')
复制，分发该文件后，在跨平台上复现
network = tf.saved<sub>model.load</sub>('model-savedmodel')
</p>
</div>
</div>
</div>
<div id="outline-container-org3128177" class="outline-3">
<h3 id="org3128177">self-def</h3>
<div class="outline-text-3" id="text-org3128177">
<p>
自定义网络层类，继承Layer
自定义网络类，继承Model
</p>
</div>
</div>
</div>

<div id="outline-container-org1dec6c9" class="outline-2">
<h2 id="org1dec6c9">regularation</h2>
<div class="outline-text-2" id="text-org1dec6c9">
</div>
<div id="outline-container-org8c17045" class="outline-3">
<h3 id="org8c17045">L0</h3>
<div class="outline-text-3" id="text-org8c17045">
<p>
控制网络中的非零权重
</p>
</div>
</div>

<div id="outline-container-org7770020" class="outline-3">
<h3 id="org7770020">L1</h3>
<div class="outline-text-3" id="text-org7770020">
<p>
网络中的所有元素的绝对值之和
促使网络生成更多的稀疏矩阵
</p>
</div>
</div>
<div id="outline-container-org0f6a4bf" class="outline-3">
<h3 id="org0f6a4bf">L2</h3>
<div class="outline-text-3" id="text-org0f6a4bf">
<p>
网络中的所有元素平方和
促使网络生成小比重的权值
</p>
</div>
</div>
</div>
<div id="outline-container-org4555ebc" class="outline-2">
<h2 id="org4555ebc">Dropout</h2>
<div class="outline-text-2" id="text-org4555ebc">
<p>
tf.nn.dropout(x, rate = 0.5)
model.add(layers.Dropout(rate=0.5))
</p>
</div>
</div>
<div id="outline-container-org542d182" class="outline-2">
<h2 id="org542d182">Data Augmentation</h2>
<div class="outline-text-2" id="text-org542d182">
</div>
<div id="outline-container-orga1bb446" class="outline-3">
<h3 id="orga1bb446">resize</h3>
<div class="outline-text-3" id="text-orga1bb446">
<p>
tf.image.resize(x,[244,244])
</p>
</div>
</div>
<div id="outline-container-org035c0c7" class="outline-3">
<h3 id="org035c0c7">rote</h3>
<div class="outline-text-3" id="text-org035c0c7">
<p>
tf.image.rot90(x,1) k为1时，代表一个90度的g逆时针旋转
</p>
</div>
</div>
<div id="outline-container-orgc854041" class="outline-3">
<h3 id="orgc854041">flip</h3>
<div class="outline-text-3" id="text-orgc854041">
<p>
tf.image.random<sub>flip</sub><sub>left</sub><sub>right</sub>(x)
tf.image.random<sub>flip</sub><sub>up</sub><sub>down</sub>(x)
</p>
</div>
</div>
<div id="outline-container-org92f9bb2" class="outline-3">
<h3 id="org92f9bb2">crop</h3>
<div class="outline-text-3" id="text-org92f9bb2">
<p>
先放大，再剪裁
tf.image.resize(x,[244,244])
tf.image.random<sub>crop</sub>(x,[224,224,3])
</p>
</div>
</div>
</div>
<div id="outline-container-org94b0034" class="outline-2">
<h2 id="org94b0034">convolution neural network</h2>
</div>


<div id="outline-container-org0db8c95" class="outline-2">
<h2 id="org0db8c95">Backlinks</h2>
</div>


<div id="outline-container-orga429ff7" class="outline-2">
<h2 id="orga429ff7">1 Backlinks</h2>
<div class="outline-text-2" id="text-orga429ff7">
</div>
<div id="outline-container-org3698520" class="outline-3">
<h3 id="org3698520"><a href="file:///home/sx/Dropbox/subjects/AI.html">AI</a></h3>
<div class="outline-text-3" id="text-org3698520">
<p>
<a href="file:///home/sx/Dropbox/Projects/tensorflow/tf2.html">tf2</a>
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: sx</p>
<p class="date">Created: 2020-06-29 Mo 22:28</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
